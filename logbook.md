# weather_contest

<details>
  <summary> 2024.06.11</summary>
  
**홈페이지 웹 R Hive를 통해 데이터 다운로드**  
  
[train] data shape = 1457252 × 21  
[test] data shape = 122000 × 20 (vv 열 제외 20개 열)

**기본 전처리**  

  열 제거 및 열이름 수정

**내일 할 일**

  fc, ef 겹치는 것으로 보여지는데 하나로 합쳐야할지 확인해보기  
  EDA, baseline, 1번 제출해보기
</details>


<details>
  <summary> 2024.06.12</summary>

**데이터 설명**

변수 : 설명                   
TM_FC : 기준 발표시각  
TM_EF : 예측 시간  
DH : 기준시각-예측 시간  
STN : AWS 지점 코드  
VO1 : 0.1 mm 이상 누적 확률 (앙상블 모델의 구간별 강수량 누적 확률)  
V02 : 0.2 mm 이상 누적 확률  
V03 : 0.5 mm 이상 누적 확률  
V04 : 1.0 mm 이상 누적 확률  
V05 : 2.0 mm 이상 누적 확률  
V06 : 5.0 mm 이상 누적 확률  
V07 : 10.0 mm 이상 누적 확률  
V08 : 20.0 mm 이상 누적 확률  
V09 : 30.0 mm 이상 누적 확률  
VV : 실강수량 (지점별 1시간 강수자료의 3시간 누적값)  
class_interval : 강수계급 (*target)  

**EDA**

1. fc_year, ef_year, stn4contest  
   A,B,C로 분류되던 년도와 지점 정보를 범주형에서 **숫자형 데이터로 변환**
   
2. 년도는 똑같지만 ( FC : 발표시각, EF : 예측시각 )에 대해 **어떻게 처리할지 고민** 

3. heatmap 그려봤는데 v01~v09 까지의 변수들이 vv에 각각 비슷한 정도의 상관성을 보임.  
   -> 뛰어난 구간이 있는 것은 아님

4. 'vv', 'class_interval' 에 -999라는 결측값이 존재 (8490/1457252) = 0.005826 % 정도니까 **제거할까?**  
   -> test 데이터에도 130개 존재 -> 별다른 예측 진행안하고 그대로 두는 행

5. 이외의 모든 vv는 125 이하인데 'vv' = 203.2 라는 값이 20개 덩그러니 있는데 하늘이 뚫린걸까...?  
   -> 3번째 년도의 8월 27일- 9월 5일까지인데... **이상치는 아닐지 고민**
</details>
